{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokumentation des Vorverarbeitungs- und Trainingsprozesses\n",
    "\n",
    "## 1. Einf√ºhrung\n",
    "\n",
    "Dieses Dokument beschreibt den **Datenvorverarbeitungsprozess** und das **Training des Modells** zur Hautkrebserkennung basierend auf Bildern. Es werden die folgenden Schritte behandelt:\n",
    "\n",
    "1. **Laden und Bereinigen des Datensatzes**\n",
    "2. **Anwendung von Transformationen und Datenaugmentierung**\n",
    "3. **Normalisierung der Metadaten**\n",
    "4. **Aufteilung in Trainings-, Validierungs- und Testdaten**\n",
    "5. **Training des Modells mit PyTorch**\n",
    "6. **Umgang mit Early Stopping und Speichern des besten Modells**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Projekteinrichtung\n",
    "\n",
    "- **Datensatz:** `data/ISIC-images`\n",
    "- **Bereinigte Metadatendatei:** `data/metadata_clean_20250226_222654.csv`\n",
    "- **Bildgr√∂√üe:** `(224, 224)`\n",
    "- **Speicherort des trainierten Modells:** `models/best_model.pth`\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Datenvorverarbeitung\n",
    "\n",
    "### 3.1 Laden des Datensatzes\n",
    "\n",
    "Die bereinigte CSV-Datei wird geladen, und vorhandene Bilder werden gefiltert.\n",
    "\n",
    "```python\n",
    "# Metadaten laden\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "CSV_PATH = \"data/metadata_clean_20250226_222654.csv\"\n",
    "DATASET_PATH = \"data/ISIC-images\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"img_path\"] = df[\"isic_id\"].apply(lambda x: os.path.join(DATASET_PATH, f\"{x}.jpg\"))\n",
    "df = df[df[\"img_path\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "```\n",
    "\n",
    "### 3.2 Datenaugmentierung und Transformationen\n",
    "\n",
    "Es wird **Albumentations** verwendet, um Transformationen auf die Bilder anzuwenden:\n",
    "\n",
    "- **Rotationen und Spiegelungen**: Simuliert verschiedene Ausrichtungen.\n",
    "- **Helligkeit und Kontrast**: Verbessert die Variabilit√§t der Hautt√∂ne.\n",
    "- **GaussianBlur und CoarseDropout**: Simuliert unscharfe oder verdeckte Bildbereiche.\n",
    "- **ElasticTransform**: Verformt das Bild leicht, um die Robustheit des Modells zu verbessern.\n",
    "\n",
    "```python\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.2),\n",
    "    A.CoarseDropout(num_holes=1, max_holes=2, max_height=20, max_width=20, p=0.3),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, p=0.2),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "```\n",
    "\n",
    "### 3.3 Normalisierung der Metadaten\n",
    "\n",
    "Die Variablen `age_approx` und `sex` werden mit `StandardScaler` normalisiert.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_metadata = scaler.fit_transform(df[[\"age_approx\", \"sex\"]])\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Aufteilung der Daten in Trainings-, Validierungs- und Testdaten\n",
    "\n",
    "Die Daten werden in Trainings- (70%), Validierungs- (15%) und Testdaten (15%) aufgeteilt.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train_img, X_temp_img, X_train_meta, X_temp_meta, y_train, y_temp = train_test_split(\n",
    "    X_images, X_metadata, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "X_val_img, X_test_img, X_val_meta, X_test_meta, y_val, y_test = train_test_split(\n",
    "    X_temp_img, X_temp_meta, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "```\n",
    "\n",
    "Die vorverarbeiteten Daten werden gespeichert:\n",
    "\n",
    "```python\n",
    "np.save(\"data/X_train_img.npy\", X_train_img)\n",
    "np.save(\"data/X_train_meta.npy\", X_train_meta)\n",
    "np.save(\"data/y_train.npy\", y_train)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Training des Modells mit PyTorch\n",
    "\n",
    "### 5.1 Trainingskonfiguration\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model import SkinCancerModel\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 5\n",
    "BEST_MODEL_PATH = \"models/best_model.pth\"\n",
    "```\n",
    "\n",
    "### 5.2 Definition des Modells\n",
    "\n",
    "```python\n",
    "model = SkinCancerModel(num_classes=2).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "```\n",
    "\n",
    "### 5.3 Training mit Early Stopping\n",
    "\n",
    "```python\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for images, metadata, labels in train_loader:\n",
    "        images, metadata, labels = images.to(DEVICE), metadata.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, metadata)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, metadata, labels in val_loader:\n",
    "            outputs = model(images, metadata)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"üõë Early stopping aktiviert\")\n",
    "            break\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Fazit\n",
    "\n",
    "- **Die Bilder und Metadaten wurden korrekt vorverarbeitet.**\n",
    "- **Der Datensatz wurde in Trainings-, Validierungs- und Testdaten aufgeteilt**, um Overfitting zu vermeiden.\n",
    "- **Das Modell wurde mit Early Stopping trainiert**, und der beste Checkpoint wurde gespeichert.\n",
    "- **Die Pipeline ist modular und wiederverwendbar** f√ºr zuk√ºnftige Modelle.\n",
    "\n",
    "**Das Modell ist bereit f√ºr Tests und weitere Optimierungen.**\n",
    "\n",
    "---\n",
    "\n",
    "**Hinweis**: Diese Dokumentation ist als lebendes Dokument gedacht. Wenn sich das Modell weiterentwickelt, werden Aktualisierungen vorgenommen, um neue Funktionen, Verbesserungen und √Ñnderungen in den Best Practices widerzuspiegeln."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
